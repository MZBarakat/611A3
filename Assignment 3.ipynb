{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Moaz Barakat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "758d2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#2 and #3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=5,random_state=0).fit(X_train, y_train)\n",
    "# Important RF parameters to consider: random_state, max_depth, n_estimators max_features \n",
    "forest = RandomForestRegressor(max_depth=5,random_state=0, n_estimators=10).fit(X_train, y_train)\n",
    "# Important GB paramerts to consider: random_state, max_depth, learning_rate, n_estimators\n",
    "gradient = GradientBoostingRegressor(max_depth=5,random_state=0, learning_rate=0.05).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3cb5d3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for DecisionTree\n",
      "training accuracy (cross-validation) 49.863\n",
      "validation accuracy (cross-validation) 79.490\n",
      "\n",
      "Score for Forest\n",
      "training accuracy (cross-validation) 33.355\n",
      "validation accuracy (cross-validation) 53.410\n",
      "\n",
      "Score for Gradient\n",
      "training accuracy (cross-validation) 7.175\n",
      "validation accuracy (cross-validation) 27.184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def print_accuracy_validation(name, model, X_train, y_train, cv_scoring, negate): #Prints and returns the training and validation scores \n",
    "    print(\"\\nScore for\", name)\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, scoring=cv_scoring,  return_train_score=True)\n",
    "\n",
    "    print('training accuracy (cross-validation) {:.3f}'.format(scores['train_score'].mean() * negate))\n",
    "    print('validation accuracy (cross-validation) {:.3f}'.format(scores['test_score'].mean() * negate))\n",
    "    return scores['train_score'].mean() * negate, scores['test_score'].mean() * negate #Note: return values used in step 5\n",
    "\n",
    "ta_1, va_1 = print_accuracy_validation(\"DecisionTree\", model=tree, X_train=X_train, y_train=y_train, cv_scoring='neg_mean_squared_error',negate=-1)\n",
    "ta_2, va_2 = print_accuracy_validation(\"Forest\", model=forest, X_train=X_train, y_train=y_train, cv_scoring='neg_mean_squared_error',negate=-1)\n",
    "ta_3, va_3 = print_accuracy_validation(\"Gradient\", model=gradient, X_train=X_train, y_train=y_train, cv_scoring='neg_mean_squared_error',negate=-1)\n",
    "\n",
    "#Real tests, not cross validated\n",
    "#val1_p = tree.score(X_test, y_test) \n",
    "#val2_p = forest.score(X_test, y_test)\n",
    "#val3_p = gradient.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring: MSE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>49.862596</td>\n",
       "      <td>79.490160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>33.355207</td>\n",
       "      <td>53.409972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>7.175423</td>\n",
       "      <td>27.184409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training accuracy  Validation accuracy\n",
       "DT          49.862596            79.490160\n",
       "RF          33.355207            53.409972\n",
       "GB           7.175423            27.184409"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "#5.2, HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "mse_results_list = [[ta_1, va_1],[ta_2,va_2],[ta_3,va_3]]\n",
    "results = pd.DataFrame(mse_results_list,columns=[\"Training accuracy\", \"Validation accuracy\"], index=['DT', 'RF', 'GB'])\n",
    "print(\"Scoring: MSE\")\n",
    "results\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for DecisionTree\n",
      "training accuracy (cross-validation) 0.821\n",
      "validation accuracy (cross-validation) 0.711\n",
      "\n",
      "Score for Forest\n",
      "training accuracy (cross-validation) 0.880\n",
      "validation accuracy (cross-validation) 0.808\n",
      "\n",
      "Score for Gradient\n",
      "training accuracy (cross-validation) 0.974\n",
      "validation accuracy (cross-validation) 0.902\n",
      "\n",
      "Scoring: R2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.821295</td>\n",
       "      <td>0.710786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.880495</td>\n",
       "      <td>0.807792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.974308</td>\n",
       "      <td>0.901926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training accuracy  Validation accuracy\n",
       "DT           0.821295             0.710786\n",
       "RF           0.880495             0.807792\n",
       "GB           0.974308             0.901926"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note function created at top simplifies code for this step\n",
    "tar_1, var_1 = print_accuracy_validation(\"DecisionTree\", model=tree, X_train=X_train, y_train=y_train, cv_scoring='r2',negate=1)\n",
    "tar_2, var_2 = print_accuracy_validation(\"Forest\", model=forest, X_train=X_train, y_train=y_train, cv_scoring='r2',negate=1)\n",
    "tar_3, var_3 = print_accuracy_validation(\"Gradient\", model=gradient, X_train=X_train, y_train=y_train, cv_scoring='r2', negate=1)\n",
    "\n",
    "r2_results_list = [[tar_1, var_1],[tar_2,var_2],[tar_3,var_3]]\n",
    "results = pd.DataFrame(r2_results_list,columns=[\"Training accuracy\", \"Validation accuracy\"], index=['DT', 'RF', 'GB'])\n",
    "print(\"\\nScoring: R2\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. From assignment 2 solution, the concrete dataset had a MSE ~`110.35/95.64` and a R2 ~`0.61/0.64` for training and validation accuracy respectively using the **linear** regression model. In contrast, using **non-linear** models all resulted in a better score as shown in the table(s) above (E.g `>0.64` R2).  Generally speaking: the higher the R2 the better (ideal value = 1) and the lower the MSE the better (ideal value = 0). We can see that the score for the non-linear model is much better than the linear model. \n",
    "\n",
    "Comparison of the models is outlined below:\n",
    "  - DT: Performed better than linear (from assignment 2)\n",
    "  - RF: Performed better than DT (evident from both MSE/R2 score)\n",
    "  - GB: Performed better than RF (evident from both MSE/R2 score)\n",
    "\n",
    "Additionally, the compressive strength is complex and nonlinear feature in nature, it makes sense that the non-linear model would do better than the linear model\n",
    "\n",
    "2. Based on the result, the validation accuracy of GB yielded the highest result. I would personally choose the GB model over the DT and RF. One thing to note is that the GB might be overfitting since the training accuracy is very close to 1. The parameters of GB can be fine-tuned/pre-pruned to resolve this issue.\n",
    "\n",
    "3. To increase the accuracy, we can fine tune the hyper parameters of the tree models and increase the complexity. Below are suggestions for each tree:\n",
    " - DT: Increase  max_depth, increase max_features\n",
    " - RF: Increase  max_depth, increase n_estimators\n",
    " - RF: Increase  max_depth, increase learning_rate\n",
    "\n",
    " More generally, we can use Grid Search to find the optimal hyper parameters\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. Where did you source your code?\n",
    " - Code is based on a combination of lectures examples and documentation from scikit learn\n",
    "  - Lecture slides adopted from: <cite>Introduction to Machine Learning with Python, Müller and Guido, 1st ed, 2016 https://github.com/amueller/introduction_to_ml_with_python</cite>\n",
    "  - Scikit learn general documentation available at: <cite> https://scikit-learn.org/stable/ </cite>\n",
    "  - Concrete dataset: <cite> https://www.scikit-yb.org/en/latest/api/datasets/concrete.html </cite>\n",
    "2. In what order did you complete the steps?\n",
    "  - The order of the steps was done as per the assignment, steps 1-5 as it seemed logically\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "  - Similar to assignment 2, I explicitly avoided using any generative AI throughout this process so I can learn while doing the assignment\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "  - No major challenges, examples on D2L really helped me a lot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Size:  2314 , Shape:  (178, 13)\n",
      "y Size:  178 , Shape:  (178,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "#import pandas as pd\n",
    "col_names = [\"Class\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \"Total phenols\", \n",
    "             \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\", \"Color intensity\", \"Hue\",\n",
    "             \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "\n",
    "wine_df = pd.read_csv(\"wine_ds/wine.data\", names=col_names)\n",
    "\n",
    "#Target is the class of wine\n",
    "X = wine_df.drop(['Class'], axis=1)\n",
    "y = wine_df['Class']\n",
    "\n",
    "print(\"X Size: \", X.size, \", Shape: \", X.shape)\n",
    "print(\"y Size: \", y.size, \", Shape: \", y.shape)\n",
    "#print(X.dtypes)\n",
    "#print(y.dtypes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol                         0\n",
      "Malic acid                      0\n",
      "Ash                             0\n",
      "Alcalinity of ash               0\n",
      "Magnesium                       0\n",
      "Total phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color intensity                 0\n",
      "Hue                             0\n",
      "OD280/OD315 of diluted wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n",
      "<bound method NDFrame._add_numeric_operations.<locals>.sum of 0      False\n",
      "113    False\n",
      "114    False\n",
      "115    False\n",
      "116    False\n",
      "       ...  \n",
      "62     False\n",
      "63     False\n",
      "64     False\n",
      "44     False\n",
      "177    False\n",
      "Name: Class, Length: 178, dtype: bool>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "nullsX = X.isnull().sum().sort_values(ascending=False)\n",
    "nullsy = y.isnull().sort_values().sum\n",
    "print(nullsX) #Note: no nulls confirmed\n",
    "print(nullsy) #Note: no nulls confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    59\n",
       "2    71\n",
       "3    48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "class_samples = wine_df.groupby(['Class']).size()\n",
    "class_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1a3055ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#2\n",
    "\n",
    "# SVC classifier\n",
    "svm = SVC(random_state=0)\n",
    "\n",
    "# Decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=3,random_state=0)\n",
    "\n",
    "#3\n",
    "svm.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "178c8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for SVC\n",
      "training accuracy (cross-validation) 0.673\n",
      "validation accuracy (cross-validation) 0.649\n",
      "\n",
      "Score for Decision Tree\n",
      "training accuracy (cross-validation) 0.993\n",
      "validation accuracy (cross-validation) 0.922\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#4\n",
    "#IMPORTANT: I re-used the function I created from step 3 in q1, this will give the cross validate results\n",
    "ta_sv_1, var_sv_1 = print_accuracy_validation(\"SVC\", model=svm, X_train=X_train, y_train=y_train, cv_scoring='accuracy',negate=1)\n",
    "ta_dt_1, var_dt_1 = print_accuracy_validation(\"Decision Tree\", model=decision_tree, X_train=X_train, y_train=y_train, cv_scoring='accuracy',negate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring: Accuracy\n",
      "          Size  Training accuracy  Validation accuracy\n",
      "SVC  (178, 13)           0.672597             0.648522\n",
      "DT   (178, 13)           0.992967             0.922414\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "acc_results_list = [[X.shape, ta_sv_1, var_sv_1],[X.shape, ta_dt_1, var_dt_1]] \n",
    "results_q2 = pd.DataFrame(acc_results_list,columns=[\"Size\",\"Training accuracy\", \"Validation accuracy\"], index=['SVC', 'DT'])\n",
    "print(\"Scoring: Accuracy\")\n",
    "print(results_q2)\n",
    "\n",
    "#Real scores: not cross validated\n",
    "#val1_p = svm.score(X_test, y_test)\n",
    "#val2_p = decision_tree.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of test data:\n",
      "0.9444444444444444\n",
      "0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "y_pred_sv = svm.predict(X_test)\n",
    "\n",
    "y_sco_dt = decision_tree.score(X_test, y_test)\n",
    "y_sco_sv = svm.score(X_test, y_test)\n",
    "\n",
    "print(\"Scores of test data:\")\n",
    "print(y_sco_dt)\n",
    "print(y_sco_sv)\n",
    "\n",
    "# The method that gave the highest accuracy is the decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(y_test.shape)\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "#ConfusionMatrixDisplay.from_predictions(y_test, \n",
    " #                                       decision_tree.predict(X_test),                             \n",
    "  #                                      cmap='rocket',\n",
    "   #                                     colorbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       0.88      1.00      0.93        14\n",
      "           3       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1. The cross validation for SVC was much lower compared to the decision tree E.g for validation accuracy SVC was `0.65` and decision tree was `0.92`. \n",
    "2. In the assignment, we were not required to scale the data for the SVC. As per lecture, the decision tree consider each feature seperatly. Therefore, the comparative magnitude of the features doesn’t matter. However, the SVC needs the data to be scaled. Therefore, we should scale the data for the SVC to work properly. Also we can graphsearch or tweak the hyper parameters\n",
    "3. Using decision tree model, 2 samples were incorrectly classified (94% accuracy)\n",
    "4. In this case, maximizing percision should be more important in the wine dataset. Depending on the situation the summary: Recall if false negative is more important, Percision if false positive is more important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "\n",
    "\n",
    "1. Where did you source your code?\n",
    " - Code is based on a combination of lectures examples and documentation from scikit learn\n",
    "  - Lecture slides adopted from: <cite>Introduction to Machine Learning with Python, Müller and Guido, 1st ed, 2016 https://github.com/amueller/introduction_to_ml_with_python</cite>\n",
    "  - Scikit learn general documentation available at: <cite> https://scikit-learn.org/stable/ </cite>\n",
    "  - Wine dataset: <cite> https://archive.ics.uci.edu/dataset/109/wine </cite>\n",
    "2. In what order did you complete the steps?\n",
    "  - The order of the steps was done as per the assignment, steps 1-5 as it seemed logically\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "  - Similar to assignment 2, I explicitly avoided using any generative AI throughout this process so I can learn while doing the assignment\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "  - No major challenges, examples on D2L really helped me a lot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "My observation include: \n",
    " - Random forest does indeed create better results than decision tree as see in Q1 (E.g ~0.7 vs ~0.8 R2 score)\n",
    " - The training scores for some of the models was pretty close to 1, this suggests overfitting\n",
    " - SVC model needed the scaler or gridsearch to be more effective. Right now it does not yield great accuracy\n",
    " - GB proved to be a good model for the concrete dataset (E.g ~0.9 R2 score)\n",
    " - DT proved to be a good model for the wine dataset (E.g ~0.92 R2 score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "what you liked or disliked: \n",
    "- I liked that we went through multiple examples of non-linear models involving classification and regression \n",
    "\n",
    "found interesting, confusing, challangeing, motivating:\n",
    "- It was intersting how the non linear model created pretty good results in comparison to the linear model. Addtionally, the example datasets were intersting and motivating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mido\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mido\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mido\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mido\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mido\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mido\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy (cross-validation) 0.926\n",
      "validation accuracy (cross-validation) 0.888\n",
      "[1 1 3 1 2 1 2 3 2 3 1 3 1 2 1 2 2 2 1 2 1 2 1 3 3 3 2 1 2 1 1 2 3 1 1 1]\n",
      "0.9444444444444444\n",
      "(36,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Decision tree classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svm = LinearSVC(max_iter=5000).fit(X_train, y_train)\n",
    "\n",
    "ta_lsv_1, var_lsv_1 = print_accuracy_validation(\"Linear SVC\", model=linear_svm, X_train=X_train, y_train=y_train, cv_scoring='accuracy',negate=1)\n",
    "\n",
    "#Test data set, no cross\n",
    "y_pred_lsv = linear_svm.predict(X_test)\n",
    "y_sco_lsv = linear_svm.score(X_test, y_test)\n",
    "\n",
    "print(y_pred_lsv)\n",
    "print(y_sco_lsv)\n",
    "\n",
    "cm_lsv = confusion_matrix(y_test, y_pred_lsv)\n",
    "print(y_test.shape)\n",
    "sns.heatmap(cm_lsv, annot=True, fmt='d', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "Based on the accuracy shown above, the confusion matrix, and the hyper parameter used Linear SVC is a good model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
